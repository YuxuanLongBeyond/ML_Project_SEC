#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Sep 26 20:10:29 2019

@author: YuxuanLong


This scripts includes several important functions for test.
"""

import numpy as np
import torch
from skimage import io, transform
import torch.utils.data as utils_data
import utils


def test_single_image(net, file, size = 384, resize = True):
    '''
    Test a single image with the trained model.
    Parameters:
        @net: the object for network model.
        @file: name of the image file for test.
        @size: the size that the image is converted to.
        @resize: boolean flag for image resize.
    Return: 
        predicted segmentation mask
        original image covered by the red mask
    '''
    
    uint_image = io.imread(file)
    test_image_origin = np.array(uint_image).astype(np.float32) / 255.0
    
    # convert the resized image to a Torch tensor with batch size 1
    if resize:
        test_image_origin = transform.resize(test_image_origin, (size, size), mode = 'constant', anti_aliasing = True)
        test_image = np.moveaxis(test_image_origin, 2, 0).astype(np.float32) # tensor format  
    else:
        test_image = test_image_origin
        test_image = np.moveaxis(test_image, 2, 0).astype(np.float32) # tensor format  
    test_image = np.expand_dims(test_image, axis = 0)
    test_image = utils.np_to_var(torch.from_numpy(test_image))  
    
    pred_test = net.forward(test_image)
    pred_np = utils.var_to_np(pred_test)[0][0] # predicted confidence map
    
    # convert prediction to binary segmentation mask
    new_mask = (pred_np >= 0.5)

    # make a red cover on the original image for visualization of segmentation result
    channel = test_image_origin[:, :, 0]
    channel[new_mask] = 1.0
    test_image_origin[:, :, 0] = channel
    mask = new_mask * 255
    return mask.astype(np.uint8), test_image_origin

def test_single_with_TTA(net, file, size = 384, resize = True):
    '''
    Test a single image with the trained model, using test time augmentation (TTA).
    Parameters:
        @net: the object for network model.
        @file: name of the image file for test.
        @size: the size that the image is converted to.
        @resize: boolean flag for image resize.
    Return: 
        predicted segmentation mask
        original image covered by the red mask
    '''

    uint_image = io.imread(file)
    test_image_origin = np.array(uint_image).astype(np.float32) / 255.0

    # resize
    if resize:
        test_image = transform.resize(test_image_origin, (size, size), mode = 'constant', anti_aliasing = True)
    else:
        test_image = test_image_origin

    # create tensor for collecting 8 images (generated by TTA)
    image_set = []
    for i in range(8):
        b1 = i // 4
        b2 = (i - b1 * 4) // 2
        b3 = i - b1 * 4 - b2 * 2
        
        # flip and rotate the image based on perturbed choice
        tem_image = utils.flip_rotate(test_image, b1, b2, b3, inverse = False)
        
        # convert to tensor format
        tem_image = np.moveaxis(tem_image, 2, 0).astype(np.float32)
        
        image_set.append(tem_image)
    image_tensor = np.array(image_set)
    
    # convert to Torch tensor variable
    image_tensor = utils.np_to_var(torch.from_numpy(image_tensor))  
    
    pred_test = net.forward(image_tensor)
    pred_np = utils.var_to_np(pred_test)
    
    pred = np.squeeze(pred_np, axis = 1)
    
    # inversely transform each prediction back to the original orientation
    for i in range(8):
        b1 = i // 4
        b2 = (i - b1 * 4) // 2
        b3 = i - b1 * 4 - b2 * 2
        pred[i] = utils.flip_rotate(pred[i], b1, b2, b3, inverse = True)
        
    # merge into one prediction
    pred = np.median(pred, axis = 0)

    # convert prediction to binary segmentation mask
    new_mask = (pred >= 0.5)

    # make a red cover on the original image for visualization of segmentation result
    channel = test_image_origin[:, :, 0]
    channel[new_mask] = 1.0
    test_image_origin[:, :, 0] = channel
    mask = new_mask * 255
    return mask.astype(np.uint8), test_image_origin
    
def test_batch_with_labels(net, file, resize = False, batch_size = 10, image_size = 384, smooth = 1.0, lam = 1.0):
    '''
    Test on a validation dataset (here we only consider BCE loss instead of focal loss).
    No TTA or ensemble used at this case.
    Parameters:
        @net: the object for network model.
        @file: root directory of the validation dataset.
        @resize: boolean flag for image resize.
        @batch_size: batch size
        @image_size: the size that the image is converted to.
        @smooth: number to be added on denominator and numerator when compute dice loss.
        @lam: weight to balance the dice loss in the final combined loss.
    Return: 
        average loss (BCE + dice) over batches
        F1 score of the test
    '''

    # keep original data
    data_augment = False
    rotate = False
    change_color = False
    test_dataset = utils.MyDataset(file, resize, data_augment, image_size, rotate, change_color)
    dataloader = utils_data.DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False)
    epoch_loss = 0.0
    numer = 0.0
    denom = 0.0
    gamma = 0.0
    loss_type = 'bce'
    Loss = utils.loss(smooth, lam, gamma, loss_type)
    for i, batch in enumerate(dataloader):
        print('Test on batch %d'%i)
        image = utils.np_to_var(batch['image'])
        mask = utils.np_to_var(batch['mask'])
        pred = net.forward(image)
        
        loss = Loss.final_loss(pred, mask)
        epoch_loss += loss.data.item() * batch_size
        
        mask = utils.var_to_np(mask)
        pred = utils.var_to_np(pred)
        numer += (mask * (pred > 0.5)).sum()
        denom += mask.sum() + (pred > 0.5).sum()
        
    epoch_loss /= len(test_dataset)
    f1 = 2.0 * numer / denom
    return epoch_loss, f1


def test_single_with_ensemble(Dlink, Dlink_plus, file, ratio = 0.6, size = 384, resize = True):
    '''
    Test a single image with the trained model, using ensemble and test time augmentation (TTA).
    Parameters:
        @Dlink: the object for D-LinkNet.
        @Dlink_plus: the object for D-LinkNet+.
        @file: name of the image file for test.
        @ratio: ratio for ensemble.
        @size: the size that the image is converted to.
        @resize: boolean flag for image resize.
    Return: 
        predicted segmentation mask
        original image covered by the red mask
    '''
    uint_image = io.imread(file)
    test_image_origin = np.array(uint_image).astype(np.float32) / 255.0

    # resize
    if resize:
        test_image = transform.resize(test_image_origin, (size, size), mode = 'constant', anti_aliasing = True)
    else:
        test_image = test_image_origin

    # create tensor for collecting 8 images (generated by TTA)
    image_set = []
    for i in range(8):
        b1 = i // 4
        b2 = (i - b1 * 4) // 2
        b3 = i - b1 * 4 - b2 * 2
        
        # flip and rotate the image based on perturbed choice
        tem_image = utils.flip_rotate(test_image, b1, b2, b3, inverse = False)
        
        # convert to tensor format
        tem_image = np.moveaxis(tem_image, 2, 0).astype(np.float32)
        
        image_set.append(tem_image)
    image_tensor = np.array(image_set)
    
    # convert to Torch tensor variable
    image_tensor = utils.np_to_var(torch.from_numpy(image_tensor))  
    
    pred_test1 = Dlink.forward(image_tensor)
    pred_test2 = Dlink_plus.forward(image_tensor)
    
    
    pred_np1 = utils.var_to_np(pred_test1)
    pred_np2 = utils.var_to_np(pred_test2)
    
    
    pred1 = np.squeeze(pred_np1, axis = 1)
    pred2 = np.squeeze(pred_np2, axis = 1)
    
    # inversely transform each prediction back to the original orientation
    for i in range(8):
        b1 = i // 4
        b2 = (i - b1 * 4) // 2
        b3 = i - b1 * 4 - b2 * 2
        pred1[i] = utils.flip_rotate(pred1[i], b1, b2, b3, inverse = True)
        pred2[i] = utils.flip_rotate(pred2[i], b1, b2, b3, inverse = True)
        
    pred = np.mean(pred1 * (1 - ratio) + pred2 * ratio, axis = 0)

    # convert prediction to binary segmentation mask
    new_mask = (pred >= 0.5)

    # make a red cover on the original image for visualization of segmentation result
    channel = test_image_origin[:, :, 0]
    channel[new_mask] = 1.0
    test_image_origin[:, :, 0] = channel
    mask = new_mask * 255
    return mask.astype(np.uint8), test_image_origin